protocol:
  smqtk:
    config:
      dataset_root: /data/datasets/M24/AR/videos
      domain: activity_recognition
      save_dir: ???
      seed: 4001
      test_ids:
      - OND.0.10001.6438158
      is_eval_enabled: true
      is_eval_roundwise_enabled: true
      has_baseline: false
      has_reaction_baseline: false
      baseline_class: ''
      use_feedback: false
      feedback_type: null
      hints: null
      resume_session: false
      resume_session_ids: null
      save_elementwise: false
      save_features: false
      feature_extraction_only: false
      feature_dir: ''
      use_saved_features: false
      use_consolidated_features: false
      use_saved_attributes: false
      algorithms:
        timesformer:
          smqtk:
            class: TimesformerAdapter
            config:
              fe_params:
                model_name: vit_base_patch16_224
                num_classes: 29
                num_perspectives: 5
                num_locations: 2
                num_relations: 52
                arch: vit
                checkpoint_file_path: ${model_root}/checkpoint_epoch_00015.pyth
                num_gpus: 1
              kl_params:
                window_size: 100
                mu_train: 1.0
                sigma_train: 0.9798755511726752
                KL_threshold: 1.9159339787124976
                decay_rate: 0.6
                num_rounds: 40
                threshold_scale: 7.0
              evm_params:
                model_path: ${model_root}/timesformer_feats_evm.hdf5
                distance_function: cosine
                gpu_idx: 0
              characterization_params:
                clustering_type: FINCH
                number_of_unknown_to_strat_clustering: 50
              dataloader_params:
                num_workers: 12
                pin_memory: true
                num_ensemble_views: 1
                num_spatial_crops: 3
                batch_size: 1
                n_threads: 0
                num_frames: 8
                sampling_rate: 32
                train_jitter_scales:
                - 256
                - 320
                test_crop_size: 224
                input_channel_num:
                - 3
              detection_threshold: 0.5
      harness:
        smqtk:
          class: LocalHarness
          config:
            data_dir: ${test_root}
            result_dir: ${test_root}/results
            gt_dir: ${test_root}/OND/activity_recognition
            gt_config: ${test_root}/OND/activity_recognition/activity_recognition.json
    class: ONDProtocol
test_root: /data/dawei.du/TimeSformer/data/
model_root: /data/dawei.du/TimeSformer/models/
